{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 - Assignment Pt II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Approval\n",
    "\n",
    "* from https://archive.ics.uci.edu/ml/datasets/Credit+Approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create seed\n",
    "import random\n",
    "\n",
    "# provide your student id as stud_id\n",
    "stud_id = 12345678\n",
    "my_seed = random.seed(stud_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sqf',\n",
       " 'gpp',\n",
       " 'xci',\n",
       " 'dva',\n",
       " 'ymu',\n",
       " 'vsf',\n",
       " 'olo',\n",
       " 'gjl',\n",
       " 'hvz',\n",
       " 'jsd',\n",
       " 'fom',\n",
       " 'wpt',\n",
       " 'jfc',\n",
       " 'dku',\n",
       " 'fhf',\n",
       " 'target']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "columns = [''.join(random.choices(string.ascii_lowercase, k=3)) for _ in range(15)]\n",
    "columns.append('target')\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1380, 16)\n",
      "  jfc    dku dva hvz   gjl wpt    gpp  fhf jsd sqf olo vsf  fom target    xci  \\\n",
      "0   g  00202   u   t  1.25   f  30.83    0   t   b   v   w    1      +  0.000   \n",
      "1   g  00043   u   t  3.04   f  58.67  560   t   a   h   q    6      +  4.460   \n",
      "2   g  00280   u   t  1.50   f  24.50  824   f   a   h   q    0      +  0.500   \n",
      "3   g  00100   u   t  3.75   t  27.83    3   t   b   v   w    5      +  1.540   \n",
      "4   s  00120   u   t  1.71   f  20.17    0   f   b   v   w    0      +  5.625   \n",
      "\n",
      "  ymu  \n",
      "0   g  \n",
      "1   g  \n",
      "2   g  \n",
      "3   g  \n",
      "4   g  \n"
     ]
    }
   ],
   "source": [
    "# construct the dataframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('week10.db')\n",
    "\n",
    "crx = pd.read_sql_query('SELECT * FROM features JOIN target USING (id)', conn)\n",
    "crx.drop('id', axis=1, inplace=True)\n",
    "crx.columns = columns\n",
    "crx = crx[np.random.default_rng(seed=my_seed).permutation(crx.columns.values)]\n",
    "print(crx.shape)\n",
    "print(crx.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns with missing values\n",
    "crx.loc[: , (crx == '?').any()].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace ? with np.nan\n",
    "import numpy as np\n",
    "\n",
    "crx.replace('?', np.nan, inplace=True)\n",
    "crx.loc[: , (crx == '?').any()].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crx.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify quasi constant values (sometimes these may be boolean features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify duplicate rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate rows if necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check of duplicate columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the variables that are duplicated or low in variance if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of the missing values are objects (strings)\n",
    "# find how many unique labels are in each feature\n",
    "for val in crx.columns.sort_values():\n",
    "    print(val, len(crx[val].dropna().unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check nulls for dataframe\n",
    "crx.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace NA with Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing data with mode and confirm isnull\n",
    "for feat in crx.columns:\n",
    "    crx[feat].fillna(crx[feat].mode()[0], inplace=True)\n",
    "    \n",
    "crx.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Dependent variable = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split; dependent variable = target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the X_train info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe basic statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "https://www.projectpro.io/recipes/deal-with-outliers-in-python\n",
    "\n",
    "* Drop\n",
    "* Mark\n",
    "* Rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print outliers by feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show X_train boxplots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalers\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html\n",
    "\n",
    "* from sklearn.preprocessing import MinMaxScaler\n",
    "* from sklearn.preprocessing import minmax_scale\n",
    "* from sklearn.preprocessing import MaxAbsScaler\n",
    "* from sklearn.preprocessing import StandardScaler\n",
    "* from sklearn.preprocessing import RobustScaler\n",
    "* from sklearn.preprocessing import Normalizer\n",
    "* from sklearn.preprocessing import QuantileTransformer\n",
    "* from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PowerTransformer scaler for outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm scaling with X_train describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm scaling with X_train boxplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm scaling by printing outliers by feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train value counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map y_train values: - = 0; + = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of categorical column names\n",
    "X_train.select_dtypes(['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify features with bi labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print X_train head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi-label mapping\n",
    "bi_labels = [...]\n",
    "\n",
    "for feat in bi_labels:\n",
    "    print(X_train[feat].value_counts())\n",
    "    bi0 = X_train[feat].value_counts().index[0]\n",
    "    bi1 = X_train[feat].value_counts().index[1]\n",
    "    X_train[feat] = X_train[feat].map({bi0:0,bi1:0})\n",
    "    X_test[feat] = X_test[feat].map({bi0:0,bi1:0})\n",
    "\n",
    "X_train.head() # confirms bi label mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding Alternatives\n",
    "\n",
    "For features with many labels\n",
    "\n",
    "* https://medium.com/analytics-vidhya/stop-one-hot-encoding-your-categorical-variables-bbb0fba89809\n",
    "* https://medium.com/swlh/stop-one-hot-encoding-your-categorical-features-avoid-curse-of-dimensionality-16743c32cea4\n",
    "* https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02 (frequency and mean encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review features with multiple labels\n",
    "for val in X_train.columns.sort_values():\n",
    "    print(val, len(X_train[val].dropna().unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify features with more than 5 features and use frequency encoding\n",
    "freq_feats = [...]\n",
    "\n",
    "for feat in freq_feats:\n",
    "    freq = X_train.groupby(feat).size()/len(X_train)\n",
    "    X_train.loc[:, feat] = X_train[feat].map(freq)\n",
    "    freq = X_test.groupby(feat).size()/len(X_test)\n",
    "    X_test.loc[:, feat] = X_test[feat].map(freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehotencode the object dtypes for features with 3 - 5 unique labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(categories='auto', drop='first', sparse=False)\n",
    "\n",
    "cat_features = [...]\n",
    "ohe_train = ohe.fit_transform(X_train[cat_features])\n",
    "ohe_train = pd.DataFrame(ohe_train, columns=ohe.get_feature_names_out(cat_features))\n",
    "ohe_train.index = X_train.index\n",
    "# use this line if you get an error\n",
    "# X_train = pd.DataFrame(ohe_train, columns=ohe.get_feature_names(cat_features))\n",
    "X_train = X_train.join(ohe_train)\n",
    "X_train.drop(cat_features, axis=1, inplace=True)\n",
    "\n",
    "ohe_test = ohe.transform(X_test[cat_features])\n",
    "ohe_test = pd.DataFrame(ohe_test, columns=ohe.get_feature_names_out(cat_features))\n",
    "ohe_test.index = X_test.index\n",
    "X_test = X_test.join(ohe_test)\n",
    "X_test.drop(cat_features, axis=1, inplace=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print X_train info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot.pie to see if target is balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values in X test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a logistic regression model\n",
    "# is it balanced? no, use class_weight='balanced'\n",
    "# is it a small dataset? yes, use liblinear for solver\n",
    "# print training score\n",
    "# print test score\n",
    "# print accuracy score\n",
    "# print rocauc score\n",
    "# print confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the recall? (derive the answer from the confusion matrix)\n",
    "# tn, fp, fn, tp is given in cell above\n",
    "# for example false negative rate (fnr) = fn / (fn + tp) so to get the fnr type fn / (fn + tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the precision? (derive the answer from the confusion matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
